{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (long short-term memory) based Recurrent NeuralNet for share price forecasting\n",
    "###### Abdulla Al Blooshi\n",
    "----------------\n",
    "- As an overview, the idea behind this model architecture is to assign weights to selected features; in this case the **open** and the **highest** price the stock reached for a given day were selected. These learned weights represents the model's view on the importance of said features from recent and previous time blocks and how they affect the price in the coming day(s).\n",
    "- This model will be trained on ADNOC's stock price history and the weights it learns will be saved and used via a transfer learning approach to be tested on and predict Borouge's future stock price.\n",
    "- This was done due to the lack of training data for Borouge's stock price as it (relatively) recently IPO'd\n",
    "<br>\n",
    "<br>\n",
    "> *This is by no means financial advice as I am not a financial expert, and all the data used here is publicly available.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow.keras as keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    LSTM\n",
    ")\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting and normalizing the data:\n",
    "   - It is easier for the model to work with numbers that are closer together; namely in the range of (0,1) for our case\n",
    "   - The `MinMaxScaler()` transformation is given by:\n",
    "      \n",
    "        X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))<br>\n",
    "        X_scaled = X_std * (max - min) + min <br>\n",
    "        \n",
    "        *where min, max = feature_range.*\n",
    "        > taken straight from the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "[[0.70333333 0.68551237]\n",
      " [0.70333333 0.68551237]\n",
      " [0.69333333 0.6819788 ]\n",
      " ...\n",
      " [0.21666667 0.17667845]\n",
      " [0.22666667 0.18374558]\n",
      " [0.3        0.25441696]] \n",
      " Validation set\n",
      "[[0.8        0.59090909]\n",
      " [0.8        0.59090909]\n",
      " [0.9        0.68181818]\n",
      " [0.86666667 0.72727273]\n",
      " [0.9        0.68181818]\n",
      " [0.73333333 0.68181818]\n",
      " [0.7        0.72727273]\n",
      " [0.93333333 0.77272727]\n",
      " [0.83333333 0.72727273]\n",
      " [0.8        0.81818182]\n",
      " [0.63333333 0.5       ]\n",
      " [0.53333333 0.31818182]\n",
      " [0.83333333 0.59090909]\n",
      " [0.83333333 0.72727273]\n",
      " [1.         0.81818182]\n",
      " [0.76666667 0.86363636]\n",
      " [0.7        0.54545455]\n",
      " [0.7        0.5       ]\n",
      " [0.5        0.5       ]\n",
      " [0.26666667 0.09090909]\n",
      " [0.46666667 0.04545455]\n",
      " [0.3        0.04545455]\n",
      " [0.56666667 0.36363636]\n",
      " [0.7        0.45454545]\n",
      " [0.8        0.5       ]\n",
      " [0.7        0.5       ]\n",
      " [0.63333333 0.5       ]\n",
      " [0.73333333 0.5       ]\n",
      " [0.73333333 0.5       ]\n",
      " [0.63333333 0.40909091]\n",
      " [0.66666667 0.36363636]\n",
      " [0.66666667 0.36363636]\n",
      " [0.53333333 0.36363636]\n",
      " [0.66666667 0.31818182]\n",
      " [0.6        0.36363636]\n",
      " [0.66666667 0.36363636]\n",
      " [0.76666667 0.5       ]\n",
      " [0.6        0.5       ]\n",
      " [0.43333333 0.31818182]\n",
      " [0.4        0.18181818]\n",
      " [0.23333333 0.        ]\n",
      " [0.43333333 0.09090909]\n",
      " [0.5        0.13636364]\n",
      " [0.43333333 0.22727273]\n",
      " [0.46666667 0.09090909]\n",
      " [0.46666667 0.22727273]\n",
      " [0.26666667 0.18181818]\n",
      " [0.         0.        ]\n",
      " [0.43333333 0.        ]\n",
      " [0.6        0.22727273]\n",
      " [0.5        0.22727273]\n",
      " [0.56666667 0.22727273]\n",
      " [0.4        0.22727273]\n",
      " [0.6        0.22727273]\n",
      " [0.46666667 0.22727273]\n",
      " [0.43333333 0.04545455]\n",
      " [0.36666667 0.        ]\n",
      " [0.43333333 0.        ]\n",
      " [0.43333333 0.04545455]\n",
      " [0.5        0.09090909]\n",
      " [0.46666667 0.13636364]\n",
      " [0.46666667 0.09090909]\n",
      " [0.56666667 0.18181818]\n",
      " [0.56666667 0.18181818]\n",
      " [0.43333333 0.13636364]\n",
      " [0.46666667 0.13636364]\n",
      " [0.5        0.22727273]\n",
      " [0.63333333 0.27272727]\n",
      " [0.63333333 0.31818182]\n",
      " [0.56666667 0.31818182]\n",
      " [0.56666667 0.22727273]\n",
      " [0.53333333 0.22727273]\n",
      " [0.6        0.31818182]\n",
      " [0.93333333 0.68181818]\n",
      " [0.83333333 0.72727273]\n",
      " [0.9        0.68181818]\n",
      " [0.63333333 0.63636364]\n",
      " [0.6        0.27272727]\n",
      " [0.63333333 0.31818182]\n",
      " [0.56666667 0.31818182]\n",
      " [0.46666667 0.27272727]\n",
      " [0.53333333 0.18181818]\n",
      " [0.5        0.18181818]\n",
      " [0.6        0.22727273]\n",
      " [0.43333333 0.18181818]\n",
      " [0.5        0.09090909]\n",
      " [0.56666667 0.18181818]\n",
      " [0.53333333 0.22727273]\n",
      " [0.56666667 0.22727273]\n",
      " [0.66666667 0.45454545]\n",
      " [0.7        0.36363636]\n",
      " [0.9        0.63636364]\n",
      " [0.93333333 1.        ]\n",
      " [0.76666667 0.72727273]\n",
      " [0.53333333 0.5       ]\n",
      " [0.43333333 0.31818182]\n",
      " [0.43333333 0.18181818]\n",
      " [0.46666667 0.13636364]\n",
      " [0.5        0.09090909]\n",
      " [0.5        0.36363636]\n",
      " [0.43333333 0.18181818]\n",
      " [0.46666667 0.09090909]\n",
      " [0.46666667 0.18181818]]\n"
     ]
    }
   ],
   "source": [
    "unsplit_dat = pd.read_csv('./data/ADNOCDIST_Historical_Data.csv', index_col='Date')\n",
    "valid_dat = pd.read_csv('./data/ADNOC_Valid.csv', index_col='Date')\n",
    "unsplit_dat\n",
    "training_set = unsplit_dat[['Open','High']].values\n",
    "valid_set = valid_dat[['Open','High']].values\n",
    "\n",
    "normalizer = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_set = normalizer.fit_transform(training_set)\n",
    "scaled_valid_set = normalizer.fit_transform(valid_set)\n",
    "print(f\"Training set\\n{scaled_train_set} \\n Validation set\\n{scaled_valid_set}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTMs distinguishing features and other important notes:\n",
    "- As per the [paper](http://www.bioinf.jku.at/publications/older/2604.pdf) first proposing this architecture by Hochreiter et al. Constant error carousels (CEC) are the central features of LSTMs. Controlling (deciding) the backward propagation of errors through the network.\n",
    "    - These CEC's are then extended to form what is referred to as a memory cell; the extension adds multiplicative input and output gates. These gates control the contents with in a cell from being propagated and control the cell from activating other units respectively.\n",
    "- RNNs are able to use recently seen previous information and cannot do so with information with larger time lags between them, this is where the LSTM architecture comes into play.\n",
    "- This is another one of the distinguishing features of using the LSTM architecture, its ability to 'remember' or erase parts of previously seen data in a window (or timestep).\n",
    "- By creating a window our training data will be turned into an array of arrays divided into chunks of N, where N would be the size of our timestep/window.\n",
    "    - for example having N be 60 would allow our model to use the previous sixty days of data to make the prediction for the 61st.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984, 60) (984,)\n"
     ]
    }
   ],
   "source": [
    "# Bismillah\n",
    "#TODO: y_train should predict close prices?\n",
    "#TODO: Consider using sklearn's standardScaler()\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "X_valid=[]\n",
    "y_valid=[]\n",
    "\n",
    "for i in range(60,scaled_train_set.shape[0]):\n",
    "    X_train.append(scaled_train_set[i-60:i,0])\n",
    "    y_train.append(scaled_train_set[i,0])\n",
    "\n",
    "for j in range(60,scaled_valid_set.shape[0]):\n",
    "    X_valid.append(scaled_valid_set[j-60:j,0])\n",
    "    y_valid.append(scaled_valid_set[j,0])\n",
    "\n",
    "# Keras accepts numpy arrays\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_valid, y_valid = np.array(X_valid), np.array(y_valid) \n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation Notes:\n",
    "- The model base architecture will be sequential which [\"_groups a linear stack of layers into a tf.keras.Model_\"](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n",
    "- Ideally I would've liked to add more dropout layers but I do not have that luxury as data is limited. The dropout layers aids in reducing the amount of overfitting.\n",
    "\n",
    "___However, before we can do that the data must be transformed further into a 3D array with X_train learning examples. In our case it will be of dimension (984,60,1), the 984 comes from the number of samples we have, the 60 is because we grouped our samples into groups of 60, and the 1 is because we want the model to access one feature at each timestep___ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
    "X_valid = np.reshape(X_valid,(X_valid.shape[0],X_valid.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60, 32)            4352      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 32)            8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 21,025\n",
      "Trainable params: 21,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=32, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "lstm_model.add(Dropout(0.1))\n",
    "lstm_model.add(LSTM(units=32, return_sequences=True))\n",
    "lstm_model.add(Dropout(0.05))\n",
    "lstm_model.add(LSTM(units=32))\n",
    "lstm_model.add(Dropout(0.05))\n",
    "lstm_model.add(Dense(units=1))\n",
    "\n",
    "\n",
    "lstm_model.summary()\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0021 - accuracy: 0.0020 - val_loss: 0.0275 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0021 - accuracy: 0.0020 - val_loss: 0.0269 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0021 - accuracy: 0.0020 - val_loss: 0.0299 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "23/31 [=====================>........] - ETA: 0s - loss: 0.0021 - accuracy: 0.0027"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\abdul\\A_$_A_P\\Borouge\\LSTM_forecaster.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/abdul/A_%24_A_P/Borouge/LSTM_forecaster.ipynb#ch0000013?line=0'>1</a>\u001b[0m lstm_model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(X_valid,y_valid))\n",
      "File \u001b[1;32mc:\\Users\\abdul\\anaconda3\\envs\\mainenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1193\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1187\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1189\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1190\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1191\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1192\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1193\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1194\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1195\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\abdul\\anaconda3\\envs\\mainenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\abdul\\anaconda3\\envs\\mainenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\abdul\\anaconda3\\envs\\mainenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\abdul\\anaconda3\\envs\\mainenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1964\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\abdul\\anaconda3\\envs\\mainenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\abdul\\anaconda3\\envs\\mainenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_model.fit(X_train, y_train, epochs=100,batch_size=32,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:orange\">TODO: ExponMovingAvg for comparison</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mainenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "214b7b0af70bfa28e0afdd81120454c4d11168c6ab8419e440f91c87a78b14e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
