{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (long short-term memory) based Recurrent NeuralNet for share price forecasting\n",
    "###### Abdulla Al Blooshi\n",
    "----------------\n",
    "- As an overview, the idea behind this model architecture is to assign weights to selected features; in this case the **open** and the **highest** price the stock reached for a given day were selected. These learned weights represents the model's view on the importance of said features from recent and previous time blocks and how they affect the price in the coming day(s).\n",
    "- This model will be trained on ADNOC's stock price history and the weights it learns will be saved and used via a transfer learning approach to be tested on and predict Borouge's future stock price.\n",
    "- This was done due to the lack of training data for Borouge's stock price as it (relatively) recently IPO'd\n",
    "<br>\n",
    "<br>\n",
    "> *This is by no means financial advice as I am not a financial expert, and all the data used here is publicly available.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras \n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    LSTM\n",
    ")\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting and normalizing the data:\n",
    "   - It is easier for the model to work with numbers that are closer together; namely in the range of (0,1) for our case\n",
    "   - The `MinMaxScaler()` transformation is given by:\n",
    "      \n",
    "        X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))<br>\n",
    "        X_scaled = X_std * (max - min) + min <br>\n",
    "        \n",
    "        *where min, max = feature_range.*\n",
    "        > taken straight from the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "[[0.70333333]\n",
      " [0.70333333]\n",
      " [0.69333333]\n",
      " [0.69      ]\n",
      " [0.68666667]\n",
      " [0.69333333]\n",
      " [0.69      ]\n",
      " [0.68666667]\n",
      " [0.70666667]\n",
      " [0.70333333]]\n",
      "Validation set\n",
      "[[0.8       ]\n",
      " [0.8       ]\n",
      " [0.9       ]\n",
      " [0.86666667]\n",
      " [0.9       ]\n",
      " [0.73333333]\n",
      " [0.7       ]\n",
      " [0.93333333]\n",
      " [0.83333333]\n",
      " [0.8       ]]\n",
      "Test set\n",
      "[[2.64]\n",
      " [2.61]\n",
      " [2.62]\n",
      " [2.62]\n",
      " [2.65]\n",
      " [2.62]\n",
      " [2.62]\n",
      " [2.6 ]\n",
      " [2.6 ]\n",
      " [2.62]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1023, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsplit_dat = pd.read_csv('./data/ADNOCDIST_Historical_Data.csv', index_col='Date')\n",
    "valid_dat = pd.read_csv('./data/ADNOC_Valid.csv', index_col='Date')\n",
    "\n",
    "\n",
    "total_set = unsplit_dat[['Open']].values\n",
    "\n",
    "# *Shuffle set to false for smaller dataset to avoid sampling bias, default behavior is shuffle first then split\n",
    "training_set, test_set = train_test_split(total_set, test_size=0.02, random_state=44, shuffle=False)\n",
    "\n",
    "valid_set = valid_dat[['Open']].values\n",
    "\n",
    "normalizer = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "scaled_train_set = normalizer.fit_transform(training_set)\n",
    "scaled_valid_set = normalizer.fit_transform(valid_set)\n",
    "# scaled_test_set = normalizer.fit_transform(test_set)\n",
    "# scaled_total_set = normalizer.fit_transform(total_set)\n",
    "\n",
    "print(f\"Training set\\n{scaled_train_set[:10]}\\nValidation set\\n{scaled_valid_set[:10]}\\nTest set\\n{test_set[:10]}\")\n",
    "training_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTMs distinguishing features and other important notes:\n",
    "- As per the [paper](http://www.bioinf.jku.at/publications/older/2604.pdf) first proposing this architecture by Hochreiter et al. Constant error carousels (CEC) are the central features of LSTMs. Controlling (deciding) the backward propagation of errors through the network.\n",
    "    - These CEC's are then extended to form what is referred to as a memory cell; the extension adds multiplicative input and output gates. These gates control the contents with in a cell from being propagated and control the cell from activating other units respectively.\n",
    "- RNNs are able to use recently seen previous information and cannot do so with information with larger time lags between them, this is where the LSTM architecture comes into play.\n",
    "- This is another one of the distinguishing features of using the LSTM architecture, its ability to 'remember' or erase parts of previously seen data in a window (or timestep).\n",
    "- By creating a window our training data will be turned into an array of arrays divided into chunks of N, where N would be the size of our timestep/window.\n",
    "    - for example having N be 60 would allow our model to use the previous sixty days of data to make the prediction for the 61st.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(963, 60) (963,)\n"
     ]
    }
   ],
   "source": [
    "#TODO: y_train should predict close prices?\n",
    "#TODO: Consider using sklearn's standardScaler()\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "X_valid=[]\n",
    "y_valid=[]\n",
    "\n",
    "for i in range(60,scaled_train_set.shape[0]):\n",
    "    X_train.append(scaled_train_set[i-60:i,0])\n",
    "    y_train.append(scaled_train_set[i,0])\n",
    "\n",
    "for j in range(60,scaled_valid_set.shape[0]):\n",
    "    X_valid.append(scaled_valid_set[j-60:j,0])\n",
    "    y_valid.append(scaled_valid_set[j,0])\n",
    "\n",
    "# Keras accepts numpy arrays\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_valid, y_valid = np.array(X_valid), np.array(y_valid) \n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation Notes:\n",
    "- The model base architecture will be sequential which [\"_groups a linear stack of layers into a tf.keras.Model_\"](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n",
    "- Ideally I would've liked to add more dropout layers but I do not have that luxury as data is limited. The dropout layers aids in reducing the amount of overfitting.\n",
    "\n",
    "___However, before we can do that the data must be transformed further into a 3D array with X_train learning examples. In our case it will be of dimension (984,60,1), the 984 comes from the number of samples we have, the 60 is because we grouped our samples into groups of 60, and the 1 is because we want the model to access one feature at each timestep___ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
    "X_valid = np.reshape(X_valid,(X_valid.shape[0],X_valid.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 60, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60, 32)            4352      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 32)            8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 21,025\n",
      "Trainable params: 21,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=32, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "lstm_model.add(Dropout(0.1))\n",
    "lstm_model.add(LSTM(units=32, return_sequences=True))\n",
    "lstm_model.add(Dropout(0.05))\n",
    "lstm_model.add(LSTM(units=32))\n",
    "lstm_model.add(Dropout(0.05))\n",
    "lstm_model.add(Dense(units=1))\n",
    "\n",
    "lstm_model.summary()\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 8s 78ms/step - loss: 0.0380 - val_loss: 0.0264\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0038 - val_loss: 0.0263\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0028 - val_loss: 0.0266\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0022 - val_loss: 0.0277\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0021 - val_loss: 0.0278\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0021 - val_loss: 0.0274\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0022 - val_loss: 0.0271\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0022 - val_loss: 0.0286\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0020 - val_loss: 0.0283\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0021 - val_loss: 0.0265\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0023 - val_loss: 0.0266\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0019 - val_loss: 0.0273\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0020 - val_loss: 0.0277\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0023 - val_loss: 0.0274\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0021 - val_loss: 0.0274\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0020 - val_loss: 0.0276\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0017 - val_loss: 0.0272\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0018 - val_loss: 0.0270\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0022 - val_loss: 0.0269\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0019 - val_loss: 0.0272\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0016 - val_loss: 0.0276\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0016 - val_loss: 0.0274\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0016 - val_loss: 0.0276\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0019 - val_loss: 0.0274\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0020 - val_loss: 0.0280\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0016 - val_loss: 0.0292\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0015 - val_loss: 0.0287\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0020 - val_loss: 0.0291\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0017 - val_loss: 0.0281\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0014 - val_loss: 0.0279\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0015 - val_loss: 0.0283\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0015 - val_loss: 0.0279\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0018 - val_loss: 0.0276\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0014 - val_loss: 0.0278\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0016 - val_loss: 0.0277\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0015 - val_loss: 0.0279\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0014 - val_loss: 0.0289\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0014 - val_loss: 0.0274\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0014 - val_loss: 0.0274\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0012 - val_loss: 0.0268\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0011 - val_loss: 0.0262\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0012 - val_loss: 0.0263\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0015 - val_loss: 0.0253\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0012 - val_loss: 0.0257\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0012 - val_loss: 0.0260\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0011 - val_loss: 0.0248\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0011 - val_loss: 0.0251\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0011 - val_loss: 0.0254\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0013 - val_loss: 0.0236\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0011 - val_loss: 0.0234\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.0011 - val_loss: 0.0231\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0011 - val_loss: 0.0228\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0010 - val_loss: 0.0235\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0011 - val_loss: 0.0235\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0011 - val_loss: 0.0258\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0012 - val_loss: 0.0238\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0010 - val_loss: 0.0234\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0010 - val_loss: 0.0233\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0011 - val_loss: 0.0232\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0012 - val_loss: 0.0238\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.0011 - val_loss: 0.0228\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0010 - val_loss: 0.0244\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0012 - val_loss: 0.0231\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0011 - val_loss: 0.0231\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 8.9823e-04 - val_loss: 0.0235\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0010 - val_loss: 0.0219\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 9.9847e-04 - val_loss: 0.0223\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 9.6087e-04 - val_loss: 0.0225\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 8.8728e-04 - val_loss: 0.0225\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 9.3952e-04 - val_loss: 0.0225\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 9.3065e-04 - val_loss: 0.0226\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.0011 - val_loss: 0.0218\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 9.9443e-04 - val_loss: 0.0219\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0011 - val_loss: 0.0213\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 9.8265e-04 - val_loss: 0.0222\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 9.9228e-04 - val_loss: 0.0213\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.0010 - val_loss: 0.0216\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 8.9725e-04 - val_loss: 0.0212\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 8.6886e-04 - val_loss: 0.0218\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 8.6575e-04 - val_loss: 0.0212\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 8.8958e-04 - val_loss: 0.0208\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 8.5818e-04 - val_loss: 0.0209\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 9.5601e-04 - val_loss: 0.0208\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 8.3712e-04 - val_loss: 0.0210\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 8.7078e-04 - val_loss: 0.0206\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 8.5865e-04 - val_loss: 0.0203\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 7.5870e-04 - val_loss: 0.0211\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 9.2797e-04 - val_loss: 0.0204\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 8.6390e-04 - val_loss: 0.0201\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 8.5620e-04 - val_loss: 0.0199\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 8.3599e-04 - val_loss: 0.0197\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.0010 - val_loss: 0.0216\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.0014 - val_loss: 0.0189\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 7.6154e-04 - val_loss: 0.0193\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 6.8800e-04 - val_loss: 0.0193\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 2s 48ms/step - loss: 7.6642e-04 - val_loss: 0.0194\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 8.0041e-04 - val_loss: 0.0193\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 8.5804e-04 - val_loss: 0.0193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21dbbb73c40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(X_train, y_train, epochs=100,batch_size=32,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model on unseen data\n",
    "\n",
    "- After training the validation loss is reasonably larger than loss on the training set, hinting towards the possibility of underfitting \n",
    "- Possible solutions are:\n",
    "    - Parameter increase\n",
    "    - Additional layers of\n",
    "    - Increased training set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense\t Dropout\t LSTM\t MinMaxScaler\t SGD\t Sequential\t X_train\t X_valid\t h5py\t \n",
      "i\t j\t keras\t lstm_model\t normalizer\t np\t os\t pd\t plt\t \n",
      "save_model\t scaled_train_set\t scaled_valid_set\t sys\t test_set\t total_set\t train_test_split\t training_set\t unsplit_dat\t \n",
      "valid_dat\t valid_set\t y_train\t y_valid\t \n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.532275 ],\n",
       "       [3.5325406],\n",
       "       [3.532654 ],\n",
       "       [3.532607 ],\n",
       "       [3.5324569],\n",
       "       [3.5321834],\n",
       "       [3.5318081],\n",
       "       [3.5313525],\n",
       "       [3.5309105],\n",
       "       [3.5304813],\n",
       "       [3.5300736],\n",
       "       [3.52966  ],\n",
       "       [3.5292363],\n",
       "       [3.5288703],\n",
       "       [3.528461 ],\n",
       "       [3.52798  ],\n",
       "       [3.5274084],\n",
       "       [3.526724 ],\n",
       "       [3.5259914],\n",
       "       [3.5254593],\n",
       "       [3.525298 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(scaled_total_set)-len(scaled_test_set)-60 = 963 = X_train.shape[0], the remaining being test\n",
    "tests=total_set[len(total_set)-len(test_set)-60:]\n",
    "tests = tests.reshape(-1,1)\n",
    "# tests = tests.reshape(-1,1)\n",
    "tests = normalizer.transform(tests)\n",
    "\n",
    "X_test=[]\n",
    "# Creating the same window and dimensions as before\n",
    "for e in range(60,tests.shape[0]):\n",
    "    X_test.append(tests[e-60:e,0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "model_prediction = lstm_model.predict(X_test)\n",
    "model_prediction = normalizer.inverse_transform(model_prediction)\n",
    "model_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_set, color='orange',label='adnoc true share price')\n",
    "# !in dire need of revision, this model needs saving xD\n",
    "# plt.plot(model_prediction, color='black',label='model prediction')\n",
    "plt.title('ADNOC share price prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Adnoc share price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('transferable.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"color:orange\">\n",
    "<li>TODO: ExponMovingAvg for comparison</li>\n",
    "<li>TODO: Data visualization</li>\n",
    "<li>TODO: Save model and use transfer learning to apply to Borouge stock</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mainenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "214b7b0af70bfa28e0afdd81120454c4d11168c6ab8419e440f91c87a78b14e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
